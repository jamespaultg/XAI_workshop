{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Explainable_AI_DE_v3_noCat.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamespaultg/XAI_workshop/blob/master/Explainable_AI_DE_v3_noCat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1REJHhxmg77Z",
        "colab_type": "text"
      },
      "source": [
        "# Explainable AI workshop\n",
        "# 0) Check setup for the Explainable AI workshop\n",
        "\n",
        "Copy the contents of the github repo 'XAI_workshop' to the folder 'XAI_workshop'.\n",
        "This will copy the data and the notebooks that we will use during the worksop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a439mwomg3E6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r XAI_workshop\n",
        "!git clone https://github.com/jamespaultg/XAI_workshop/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPrQcVlKhSqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install lime -q\n",
        "!pip install shap -q\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bhKZh3bhzMT",
        "colab_type": "text"
      },
      "source": [
        "## 1) Load required libraries and data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pt2uJ6ewiBA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load required libraries\n",
        "\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# For converting textual categories to integer labels \n",
        "from sklearn.preprocessing import LabelEncoder#\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV # for creating train test split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "#from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve, auc, make_scorer, confusion_matrix, f1_score, fbeta_score, classification_report\n",
        "\n",
        "# Our algorithms, by from the easiest to the hardest to intepret.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "\n",
        "import lightgbm as lgb\n",
        "\n",
        "\n",
        "print('libraries loaded')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XeoxyYUluyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading the titanic data\n",
        "df_titanic = pd.read_csv('XAI_workshop/data/titanic.csv')\n",
        "assert len(df_titanic) == 891, 'There is an error. Please email james gnanasekaran with the details of the error message you get'\n",
        "df_titanic.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2lp5NRUiyRv",
        "colab_type": "text"
      },
      "source": [
        "# 2) Data preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYz4_YXOAIfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_titanic.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc_CdWdE_7as",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data preparation\n",
        "df_titanic.fillna(0,inplace=True)\n",
        "\n",
        "# label encoding textual data\n",
        "le = LabelEncoder()\n",
        "df_titanic['Sex_le'] = le.fit_transform(df_titanic['Sex'])\n",
        "\n",
        "features = [\"PassengerId\", \"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Sex_le\"]\n",
        "\n",
        "preprocessor = ColumnTransformer([(\"numerical\", \"passthrough\", features)])\n",
        "\n",
        "X = df_titanic[features]\n",
        "y = df_titanic['Survived']\n",
        "\n",
        "# using train test split to create validation set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42, stratify = y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIL5XJS_N60_",
        "colab_type": "text"
      },
      "source": [
        "**!Question general 1!** What is the percentage of people in the data surviving?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlNyRZ2bKBg_",
        "colab_type": "text"
      },
      "source": [
        "# 3) Creating pipelines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cY1UbtFA5AJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Logistic Regression\n",
        "lr_model = Pipeline([(\"preprocessor\", preprocessor), \n",
        "                     (\"model\", LogisticRegression(class_weight=\"balanced\", solver=\"liblinear\", random_state=42))])\n",
        "\n",
        "# Random Forest\n",
        "rf_model = Pipeline([(\"preprocessor\", preprocessor), \n",
        "                     (\"model\", RandomForestClassifier(class_weight=\"balanced\", n_estimators=100, n_jobs=-1))])\n",
        "\n",
        "# XGBoost\n",
        "xgb_model = Pipeline([(\"preprocessor\", preprocessor), \n",
        "                      # Add a scale_pos_weight to make it balanced\n",
        "                      (\"model\", XGBClassifier(scale_pos_weight=(1 - y.mean()), n_jobs=-1))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwD82E_SBACC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Logistic Regression\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = lr_model.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEb5-GlrRH-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Random Forest\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgrBRVlcCnGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# XG boost\n",
        "\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUjasdEsORfU",
        "colab_type": "text"
      },
      "source": [
        "**!Question general 2!** The classification reports provide a lot of numbers, but what do they mean? What is the difference between precision and recall? And what could be a reason that both models show better f1-scores for group 0 than 1? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJ4qOhwcKQSd",
        "colab_type": "text"
      },
      "source": [
        "# 4) Lime\n",
        "\n",
        "Lime (Local Interpretable Model-Agnostic Explanations) is setup by following three steps:\n",
        "\n",
        "1. Create a new explainer\n",
        "  - my expaliner = Explainer()\n",
        "\n",
        "2. Select an observation and create an explanation for it\n",
        "  - observation = np.array([...]) -> note that this is not a pandas dataframe as used in the scikit pipelines\n",
        "  - my_explanation = explainer.explain_instance(observation, predict_function)\n",
        "\n",
        "3. Use methods on explantion to visaulise results\n",
        "  - my_explantion.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7QCv1R_HFKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lime.lime_tabular import LimeTabularExplainer\n",
        "\n",
        "\n",
        "explainer = LimeTabularExplainer(X_train.values,\n",
        "                                 mode = \"classification\",\n",
        "                                 feature_names = X_train.columns.values.tolist(),\n",
        "                                 discretize_continuous = True,\n",
        "                                 random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUylqdOdHdTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Explanation for the different models\n",
        "observation_to_explain = 23\n",
        "\n",
        "observation = X_test.iloc[[observation_to_explain], :].values[0]\n",
        "observation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paCEZzecP2U8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let write a custom predict_proba functions for our models:\n",
        "from functools import partial\n",
        "\n",
        "def custom_predict_proba(X, model):\n",
        "    X_str = pd.DataFrame(X, columns = X_train.columns)\n",
        "    return model.predict_proba(X_str)\n",
        "\n",
        "lr_predict_proba = partial(custom_predict_proba, model=lr_model)\n",
        "rf_predict_proba = partial(custom_predict_proba, model=rf_model)\n",
        "xgb_predict_proba = partial(custom_predict_proba, model=xgb_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EGc8sEqIVpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## logistic regression\n",
        "j=10\n",
        "explanation = explainer.explain_instance(X_test.values[j], lr_predict_proba, num_features=5)\n",
        "explanation.show_in_notebook(show_table=True, show_all=False)\n",
        "print(explanation.local_exp)\n",
        "print(explanation.score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1uwtFg9lu1q",
        "colab_type": "text"
      },
      "source": [
        "## There are three parts to the explanation :\n",
        "- Left most part gives the prediction probabilities for class 0 and class 1.\n",
        "- Middle part gives the 5 most important features. As it is an example of binary class we are looking at 2 colours. Attributes having orange colour support the class 1 and those with colour blue support class 0. Sex_le ≤0 means when this feature’s value satisfy this criteria it support class 0. Float point number on the horizontal bars represent the relative importance of these features.\n",
        "- Right most part follows the same colour coding as the left and the middle part. It contains the actual values of for the top 5 variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMVYMHujSX7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## XG-boost \n",
        "\n",
        "explanation = explainer.explain_instance(observation, xgb_predict_proba, num_features=5)\n",
        "explanation.show_in_notebook(show_table=True, show_all=False)\n",
        "print(explanation.score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8CPlNFqNTx8",
        "colab_type": "text"
      },
      "source": [
        "**!Question LIME 1!** After examining a few of the observations in the test set, which variables are typically the main drivers behind the different models?  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RExudQxMqHw",
        "colab_type": "text"
      },
      "source": [
        "**!Question LIME 2!** How is Lime different from more general feature importance methods? I.e. when would you use Lime and when would you use feature importance methods?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEPasUIXLUUF",
        "colab_type": "text"
      },
      "source": [
        "**!Question LIME 3!**\n",
        "Why is it necessary to provide the Explainer with the entire table X_train? What is this table used for by the Explainer?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggqe6W8TLt3g",
        "colab_type": "text"
      },
      "source": [
        "**!Question LIME 4!** Why can't we use the normal predict_proba function? And do we have to use the custom_predict_proba function? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goCgn7xPMEeG",
        "colab_type": "text"
      },
      "source": [
        "**!Question LIME 5!** What does the explanation.score depict. And why is it not suprising for the score to be higher for the logistic regression model compared to the XG-boost model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihS5s4TmPHn_",
        "colab_type": "text"
      },
      "source": [
        "**EXTRA HARD QUESTION** To start of easy we removed all the catagorical variables from the data, but Lime is able to interpret catagorical variables (as can be seen in the Explainer() documentation). Adjust the whole code such that catagorical variable are taken into account. Start by using the OneHotEncoder  instead of the LabelEncoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW7HnYpvlu49",
        "colab_type": "text"
      },
      "source": [
        "# 5) Where can I find more resources?\n",
        "\n",
        "- Link to the original LIME paper 'Why should I trust you' - https://arxiv.org/abs/1602.04938\n",
        "- Github link : https://github.com/marcotcr/lime\n",
        "\n",
        "- https://www.oreilly.com/learning/introduction-to-local-interpretable-model-agnostic-explanations-lime\n",
        "- https://blog.dominodatalab.com/shap-lime-python-libraries-part-2-using-shap-lime/\n"
      ]
    }
  ]
}